# -*- coding: utf-8 -*-
"""performance_evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mUVLOAcUCRRk1EkyftEVMcw3x2Xb4bSl
"""

import numpy as np

def calculate_metrics(cm):
    """
    Calculate performance metrics from the confusion matrix.
    :param cm: Confusion matrix as a 2x2 NumPy array.
    :return: Dictionary of calculated metrics (Accuracy, Precision, Recall, FPR, FNR, etc.).
    """
    tp = cm[1, 1]
    tn = cm[0, 0]
    fp = cm[0, 1]
    fn = cm[1, 0]

    accuracy = (tp + tn) / np.sum(cm)
    precision = tp / (tp + fp) if (tp + fp) != 0 else 0
    recall = tp / (tp + fn) if (tp + fn) != 0 else 0
    fpr = fp / (fp + tn) if (fp + tn) != 0 else 0
    fnr = fn / (fn + tp) if (fn + tp) != 0 else 0

    return {
        "Accuracy": accuracy,
        "Precision": precision,
        "Recall": recall,
        "FPR": fpr,
        "FNR": fnr
    }

if __name__ == "__main__":
    # Example usage
    cm = np.array([[50, 10], [5, 35]])  # Example confusion matrix
    metrics = calculate_metrics(cm)
    print("Performance Metrics:")
    for key, value in metrics.items():
        print(f"{key}: {value:.4f}")